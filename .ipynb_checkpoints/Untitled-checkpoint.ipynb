{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "NN_ApprenticeRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from LoadData import *\n",
    "from Measure import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def MeasureResult(themap, thendcg):\n",
    "    string=str(themap)+'\\t'\n",
    "    for ndcg in thendcg:\n",
    "        string += str(ndcg)+'\\t'\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class RL(object):\n",
    "    def __init__(self, Nfeature, Learningrate, Lenepisode, Resultfile):\n",
    "\n",
    "        self.Nfeature = Nfeature\n",
    "        self.Lenepisode = Lenepisode\n",
    "\n",
    "        self.W=np.random.rand(Nfeature)\n",
    "        # self.W = np.zeros(Nfeature)\n",
    "        self.lr = Learningrate\n",
    "\n",
    "        self.resultfile = open(Resultfile, 'w')\n",
    "        self.resultfile_w = open(Resultfile + '_W', 'w')\n",
    "\n",
    "        self.Ntop = 10\n",
    "        self.memory=[]\n",
    "        \n",
    "        \n",
    "        hidden_units=10\n",
    "        \n",
    "        global scores, input_docs, position, learning_rate, sess, train_step, cross_entropy, grads_vars, prob\n",
    "        \n",
    "        input_docs = tf.placeholder(tf.float32, [None, self.Nfeature])\n",
    "        position = tf.placeholder(tf.int64)\n",
    "        learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "        \n",
    "        # Generate hidden layer\n",
    "        W1 = tf.Variable(tf.truncated_normal([self.Nfeature, hidden_units], stddev=0.1 / np.sqrt(float(Nfeature))))\n",
    "        #b1 = tf.Variable(tf.zeros([1, hidden_units]))\n",
    "        h1 = tf.tanh(tf.matmul(input_docs, W1))\n",
    "\n",
    "        # Second layer -- linear classifier for action logits\n",
    "        W2 = tf.Variable(tf.truncated_normal([hidden_units, 1], stddev=0.1 / np.sqrt(float(hidden_units))))\n",
    "        #b2 = tf.Variable(tf.zeros([1]))\n",
    "        scores = tf.transpose(tf.matmul(h1, W2)) #+ b2 \n",
    "        prob = tf.nn.softmax(scores)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = prob, labels=position)\n",
    "        #train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "        opt = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        grads_vars = opt.compute_gradients(cross_entropy)\n",
    "        train_step = opt.apply_gradients(grads_vars)\n",
    "        \n",
    "        # Start TF session\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        #train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "\n",
    "    def GenEpisodes(self, Queryids, Data):\n",
    "\n",
    "        thendcg = np.zeros(self.Ntop)\n",
    "        themap = 0.0\n",
    "\n",
    "        nquery = len(Queryids)\n",
    "\n",
    "        for queryid in Queryids:\n",
    "            QueryInfo = Data[queryid]\n",
    "            \n",
    "            score = sess.run([scores], feed_dict={input_docs:QueryInfo['feature']})[0].reshape([-1])\n",
    "\n",
    "            ndoc = len(score)\n",
    "            positions = range(ndoc)\n",
    "            ranklist = np.zeros(ndoc, dtype=np.int32)\n",
    "\n",
    "            # scoretmp = score.tolist()\n",
    "            labeltmp = QueryInfo['label'].tolist()\n",
    "\n",
    "            for position in range(ndoc):\n",
    "                choice = np.argmax(labeltmp)\n",
    "                ranklist[position] = positions[choice]\n",
    "\n",
    "                del labeltmp[choice]\n",
    "                del positions[choice]\n",
    "\n",
    "            reward = GetReturn(QueryInfo['label'][ranklist])\n",
    "\n",
    "            self.memory.append({'queryid': queryid, 'score': score, 'reward': reward, 'ranklist': ranklist})\n",
    "\n",
    "            rates = QueryInfo['label'][ranklist]\n",
    "            themap += MAP(rates)\n",
    "            thendcg += NDCG(self.Ntop, rates)\n",
    "\n",
    "        themap=themap/nquery\n",
    "        thendcg = thendcg / nquery\n",
    "\n",
    "        print  'train: ', themap, thendcg[0], thendcg[2], thendcg[5], thendcg[9],\n",
    "\n",
    "        self.resultfile.write(MeasureResult(themap, thendcg))\n",
    "\n",
    "\n",
    "    def UpPolicy(self, Data):\n",
    "        \n",
    "        for item in self.memory:\n",
    "            queryid = item['queryid']\n",
    "            score = item['score']\n",
    "            reward = item['reward']\n",
    "            ranklist = item['ranklist']\n",
    "\n",
    "            QueryInfo = Data[queryid]\n",
    "\n",
    "            ndoc = len(ranklist)\n",
    "            delta_query = np.zeros(self.Nfeature)\n",
    "\n",
    "            lenghth = min(self.Lenepisode, ndoc)\n",
    "            \n",
    "            for pos  in range(lenghth):\n",
    "                \n",
    "                loss,_ = sess.run([cross_entropy, train_step], feed_dict={input_docs:QueryInfo['feature'][ranklist], position:[0], learning_rate:self.lr*reward[pos]})\n",
    "#                 print loss[0],self.lr*reward[pos]\n",
    "#                     print QueryInfo['feature'][ranklist]\n",
    "                    \n",
    "#                     gradients_and_vars, prosb = sess.run([grads_vars, prob], feed_dict={input_docs:QueryInfo['feature'][ranklist], position:[0]})\n",
    "                    \n",
    "#                     print prosb\n",
    "                    \n",
    "#                     for g, v in gradients_and_vars:\n",
    "#                         if g is not None:\n",
    "#                             print \"****************this is variable*************\"\n",
    "#                             print v\n",
    "#                             print \"****************this is gradient*************\"\n",
    "#                             print g\n",
    "                            \n",
    "                ranklist = np.delete(ranklist, 0)                            \n",
    "\n",
    "        # print delta\n",
    "        del self.memory[:]\n",
    "\n",
    "\n",
    "\n",
    "    def Eval(self, Data, type):\n",
    "\n",
    "        thendcg = np.zeros(self.Ntop)\n",
    "        themap = 0.0\n",
    "\n",
    "        nquery = len(Data.keys())\n",
    "\n",
    "        for queryid in Data.keys():\n",
    "            QueryInfo = Data[queryid]\n",
    "            \n",
    "            score = sess.run(scores, feed_dict={input_docs:QueryInfo['feature']})[0].reshape([-1])\n",
    "            \n",
    "#             print score[0],\n",
    "\n",
    "            rates = QueryInfo['label'][np.argsort(score)[np.arange(len(score) - 1, -1, -1)]]\n",
    "\n",
    "            themap += MAP(rates)\n",
    "            thendcg += NDCG(self.Ntop, rates)\n",
    "\n",
    "            # print NDCG/nquery\n",
    "        themap = themap / nquery\n",
    "        thendcg = thendcg / nquery\n",
    "        self.resultfile.write(MeasureResult(themap, thendcg))\n",
    "\n",
    "        if type == 'test':\n",
    "            self.resultfile.write('\\n')\n",
    "\n",
    "        print type, ':  ',themap, thendcg[0], thendcg[2], thendcg[5], thendcg[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "MSLR-WEB10K <_sre.SRE_Match object at 0x4f9eeb8> None\n",
      "-0.0148489 test :   0.845261172105 0.2 0.213271 0.15708 0.130378\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.0137413 test :   0.845477895549 0.2 0.213271 0.15708 0.130378\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.0127057 test :   0.836629777172 0.2 0.213271 0.15782 0.135163\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.0117288 test :   0.816627951744 0.2 0.253396 0.184556 0.155254\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.0107973 test :   0.812428165394 0.0 0.076019 0.065626 0.171952\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.00989762 test :   0.803076930844 0.0 0.0 0.157319 0.243313\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.00901574 test :   0.801213180867 0.0 0.015988 0.15953 0.252613\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.0081372 test :   0.79933861934 0.0 0.015988 0.15953 0.252613\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.00724687 test :   0.798112792259 0.0 0.015988 0.107276 0.249502\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.00632885 test :   0.796965066252 0.0 0.015988 0.15953 0.254427\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.00536627 test :   0.79997664906 0.0 0.015988 0.224544 0.271645\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.00434119 test :   0.801530086861 0.0 0.02534 0.283029 0.285379\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.00323444 test :   0.8061336669 0.066667 0.02534 0.283029 0.285379\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.0020254 test :   0.807025183159 0.066667 0.02534 0.283029 0.285928\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.000691908 test :   0.808693779246 0.066667 0.02534 0.283029 0.342311\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.000789864 test :   0.809598287613 0.066667 0.02534 0.292393 0.348187\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.00244553 test :   0.809385397458 0.066667 0.02534 0.214013 0.344986\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0043027 test :   0.824338346846 0.066667 0.453396 0.450983 0.487851\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.00639095 test :   0.837345235401 0.066667 0.341171 0.44122 0.520071\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.00874189 test :   0.841512221046 0.066667 0.341171 0.44122 0.549553\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0113893 test :   0.852044004628 0.066667 0.341171 0.4353 0.57566\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.014369 test :   0.853690417741 0.066667 0.341171 0.4353 0.57566\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0177191 test :   0.854308817956 0.066667 0.341171 0.4353 0.57566\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0214795 test :   0.854986542712 0.066667 0.341171 0.44122 0.580108\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0256923 test :   0.855883639664 0.066667 0.341171 0.502837 0.590255\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0304012 test :   0.855966256806 0.066667 0.341171 0.502837 0.592576\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0356513 test :   0.856520374347 0.066667 0.341171 0.508757 0.597024\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0414888 test :   0.856732624806 0.066667 0.341171 0.56101 0.600135\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0479603 test :   0.856937256709 0.066667 0.341171 0.56101 0.603414\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0551119 test :   0.855862533463 0.066667 0.341171 0.56101 0.638104\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0629877 test :   0.855195285633 0.066667 0.341171 0.56101 0.638104\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0716287 test :   0.855487478246 0.066667 0.341171 0.56101 0.670124\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0810702 test :   0.854647835828 0.066667 0.341171 0.56101 0.670124\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0913394 test :   0.854483145446 0.066667 0.341171 0.56101 0.670124\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.102452 test :   0.854804413383 0.066667 0.341171 0.56101 0.670124\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.114409 test :   0.854250670729 0.066667 0.341171 0.56101 0.670124\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.127193 test :   0.852907616392 0.066667 0.341171 0.56101 0.670124\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.140764 test :   0.853117361041 0.066667 0.341171 0.56101 0.670124\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.155058 test :   0.850928527646 0.066667 0.453396 0.635788 0.680483\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.169981 test :   0.849183274197 0.066667 0.453396 0.635788 0.678285\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.185413 test :   0.849183274197 0.066667 0.453396 0.635788 0.675565\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.201208 test :   0.848107886637 0.066667 0.453396 0.557407 0.667416\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.217195 test :   0.847006850451 0.066667 0.645246 0.575056 0.623388\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.233185 test :   0.845781411488 0.066667 0.645246 0.575056 0.620641\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.248977 test :   0.84434450616 0.066667 0.645246 0.575056 0.61724\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.264367 test :   0.844651813569 0.066667 0.645246 0.575056 0.61724\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.279151 test :   0.843425853449 0.066667 0.453396 0.557407 0.599625\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.293137 test :   0.840061464215 0.066667 0.453396 0.526713 0.590119\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.306148 test :   0.840339374207 0.066667 0.453396 0.526713 0.593601\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.318025 test :   0.840339374207 0.066667 0.453396 0.526713 0.593601\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.328634 test :   0.840344160412 0.066667 0.453396 0.526713 0.593601\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.337863 test :   0.840135858639 0.066667 0.341171 0.451936 0.53741\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.345625 test :   0.840203977527 0.066667 0.341171 0.451936 0.53741\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.351855 test :   0.83777181894 0.066667 0.341171 0.434379 0.526937\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.356511 test :   0.837730716834 0.066667 0.341171 0.434379 0.526937\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.359568 test :   0.83754063109 0.066667 0.341171 0.434379 0.529135\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.361021 test :   0.837836582635 0.066667 0.341171 0.434379 0.529135\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.360876 test :   0.837684116495 0.066667 0.341171 0.434379 0.574967\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.359152 test :   0.837651217308 0.066667 0.341171 0.434379 0.574967\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.35588 test :   0.834827811885 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.351095 test :   0.835027651967 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.344838 test :   0.834846445634 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.337154 test :   0.834936004436 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.328088 test :   0.835173235886 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.317685 test :   0.835263815596 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.305988 test :   0.835353694947 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.293037 test :   0.835437754864 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.278868 test :   0.835309349244 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.26351 test :   0.835488647005 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.246986 test :   0.835550228248 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.229314 test :   0.83527824836 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.210502 test :   0.835280745454 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.19055 test :   0.83465810966 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.169451 test :   0.834537257994 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.147186 test :   0.834773674925 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.12373 test :   0.835252093196 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0990485 test :   0.835366514208 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0730978 test :   0.835462547658 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.0458279 test :   0.835348819876 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 0.017183 test :   0.835348819876 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.0128966 test :   0.835513109806 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.0444704 test :   0.835816894821 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.0775947 test :   0.835884072559 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.112317 test :   0.835918867033 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.148671 test :   0.836362411714 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.186671 test :   0.836477987896 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.226306 test :   0.836142476913 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.267539 test :   0.836070942053 0.066667 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.310303 test :   0.836935226669 0.2 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.354509 test :   0.836205268144 0.2 0.101358 0.401219 0.550049\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.400047 test :   0.832732788532 0.2 0.092006 0.394987 0.545367\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.446799 test :   0.832383913739 0.2 0.092006 0.394987 0.545367\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.494644 test :   0.833160281891 0.2 0.092006 0.394987 0.545367\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.543472 test :   0.832752184174 0.2 0.092006 0.394987 0.545367\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.593187 test :   0.832633281689 0.2 0.092006 0.394987 0.545367\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.643713 test :   0.832987918431 0.2 0.092006 0.394987 0.545367\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.694994 test :   0.831914790119 0.2 0.092006 0.394987 0.545367\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.746992 test :   0.832172001125 0.2 0.315831 0.425936 0.568623\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.799686 test :   0.832280014528 0.2 0.315831 0.425936 0.568623\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.853065 test :   0.833074534878 0.2 0.315831 0.442323 0.580937\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.907126 test :   0.832850626004 0.2 0.315831 0.442323 0.580937\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -0.961867 test :   0.83298565338 0.2 0.315831 0.442323 0.580937\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.01729 test :   0.832458589459 0.2 0.315831 0.442323 0.580937\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.07338 test :   0.832360640571 0.2 0.315831 0.442323 0.580937\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.13014 test :   0.83191385483 0.2 0.315831 0.442323 0.580937\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.18755 test :   0.831700125781 0.2 0.315831 0.442323 0.580937\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.24559 test :   0.831604961556 0.2 0.315831 0.452682 0.588721\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.30423 test :   0.831382091946 0.2 0.315831 0.544126 0.594165\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.36346 test :   0.831357295198 0.2 0.315831 0.544126 0.594165\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.42322 test :   0.830953332457 0.2 0.315831 0.544126 0.594165\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.48349 test :   0.831364814949 0.2 0.315831 0.544126 0.594165\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.54423 test :   0.831267271097 0.2 0.315831 0.544126 0.594165\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.6054 test :   0.83198419473 0.2 0.315831 0.544126 0.594165\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.66695 test :   0.833149115818 0.2 0.315831 0.544126 0.594165\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.72885 test :   0.832957109522 0.2 0.315831 0.544126 0.594165\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.79107 test :   0.833186678012 0.2 0.315831 0.544126 0.601401\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.85355 test :   0.833722500052 0.2 0.315831 0.544126 0.603965\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.91627 test :   0.833478836124 0.2 0.315831 0.544126 0.657436\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -1.97919 test :   0.833451020054 0.2 0.315831 0.544126 0.657436\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.04229 test :   0.833576796584 0.2 0.315831 0.544126 0.603965\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.10554 test :   0.833356775043 0.2 0.315831 0.544126 0.603965\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.16892 test :   0.832853919372 0.2 0.315831 0.544126 0.603965\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.23242 test :   0.8333773776 0.2 0.315831 0.544126 0.603965\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.29603 test :   0.836865076405 0.2 0.456113 0.637598 0.674204\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.35975 test :   0.837091906245 0.2 0.456113 0.637598 0.674204\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.4236 test :   0.839720801695 1.0 0.695925 0.670758 0.699122\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.48758 test :   0.839818257634 1.0 0.80815 0.745535 0.755313\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.55172 test :   0.839761339762 1.0 0.80815 0.745535 0.755313\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.61606 test :   0.840514169068 1.0 0.80815 0.745535 0.755313\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.68062 test :   0.842020898611 1.0 0.80815 0.745535 0.755313\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.74546 test :   0.842311085339 1.0 0.80815 0.745535 0.755313\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.8106 test :   0.842954134892 1.0 0.80815 0.745535 0.755313\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.87611 test :   0.846768194924 1.0 1.0 0.800719 0.796781\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -2.942 test :   0.848246351441 1.0 1.0 0.814765 0.807335\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.00832 test :   0.847737732138 1.0 1.0 0.814765 0.807335\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.07507 test :   0.848333599501 1.0 1.0 0.814765 0.807335\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.14226 test :   0.849318565324 1.0 1.0 0.814765 0.807335\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.20984 test :   0.852542495275 1.0 1.0 0.921619 0.824193\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.27779 test :   0.855201163301 1.0 1.0 1.0 0.835925\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.34602 test :   0.855309564642 1.0 1.0 1.0 0.835472\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.41444 test :   0.855532785661 1.0 1.0 1.0 0.835472\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.48293 test :   0.855563445893 1.0 1.0 1.0 0.835472\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.55136 test :   0.855716131222 1.0 1.0 1.0 0.835472\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.61962 test :   0.856868519776 1.0 1.0 1.0 0.894959\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.68755 test :   0.858719338191 1.0 1.0 1.0 0.894959\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.75505 test :   0.860064947441 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.82199 test :   0.860265121295 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.88826 test :   0.860097720771 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -3.95377 test :   0.859591576691 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.01846 test :   0.859829760151 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.08224 test :   0.860376255799 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.14508 test :   0.861682849553 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.20692 test :   0.861888004056 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.26775 test :   0.862415683345 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.32753 test :   0.863060927919 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.38627 test :   0.863592461304 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.44394 test :   0.863469791447 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.50056 test :   0.864372194718 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.55613 test :   0.864793593484 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.61066 test :   0.865294142551 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.66416 test :   0.865706778664 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.71665 test :   0.866230751436 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.76816 test :   0.866428850379 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.81871 test :   0.866310247751 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.86832 test :   0.866144075868 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.91702 test :   0.866451653202 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -4.96484 test :   0.866390109927 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.01182 test :   0.866390109927 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.05797 test :   0.86712623359 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.10335 test :   0.86664913797 1.0 1.0 1.0 0.940791\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.14796 test :   0.867436058946 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.19186 test :   0.867526242169 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.23507 test :   0.867748558651 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.27762 test :   0.867952497287 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.31954 test :   0.867917000741 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.36087 test :   0.86802478945 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.40163 test :   0.867727294498 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.44184 test :   0.869050944598 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.48153 test :   0.869188557012 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.52073 test :   0.869263673601 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.55946 test :   0.869914118872 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.59773 test :   0.869928065036 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.63556 test :   0.869500531392 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.67296 test :   0.869774554044 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.70995 test :   0.86992786535 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.74653 test :   0.870062582727 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.7827 test :   0.869837315758 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.81847 test :   0.870374062458 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.85383 test :   0.87002517114 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.88879 test :   0.86974284556 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.92334 test :   0.870022727986 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.95746 test :   0.870218809312 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -5.99115 test :   0.870423390199 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -6.02441 test :   0.870396374832 1.0 1.0 1.0 0.936728\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -6.05721 test :   0.870847906067 1.0 1.0 0.908556 0.931285\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -6.08955 test :   0.871535638263 1.0 1.0 0.898197 0.923501\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -6.12142 test :   0.871967741722 1.0 1.0 0.898197 0.923501\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -6.1528 test :   0.87184701349 1.0 1.0 0.88181 0.911187\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -6.18369 test :   0.871814309695 1.0 1.0 0.88181 0.911187\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -6.21408 test :   0.871489957018 1.0 0.776175 0.850861 0.887931\n",
      "train:  1.0 1.0 1.0 1.0 1.0 -6.24395 test :   0.871239715143 1.0 0.776175 0.850861 0.857376\n"
     ]
    }
   ],
   "source": [
    "dataset = 'MSLR-WEB10K'\n",
    "\n",
    "train_data = LoadData('data', dataset)\n",
    "nquery = len(train_data.keys())\n",
    "\n",
    "Nfeature=136\n",
    "Learningrate=0.0001\n",
    "Nepisode=10\n",
    "\n",
    "Lenepisode=10\n",
    "\n",
    "Resultfile = 'ApprenticeRank/Result_Data_'\n",
    "\n",
    "\n",
    "learner = RL(Nfeature, Learningrate, Lenepisode, Resultfile)\n",
    "learner.Eval(train_data, 'test')\n",
    "\n",
    "\n",
    "for ite in range(200):\n",
    "    batch = np.random.randint(nquery,size=Nepisode)\n",
    "    \n",
    "    Queryids=[]\n",
    "    for i in batch:\n",
    "        Queryids.append(train_data.keys()[i])\n",
    "        \n",
    "    learner.GenEpisodes(Queryids, train_data)\n",
    "    learner.UpPolicy(train_data)\n",
    "    learner.Eval(train_data,'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zengwei/data/MSLR-WEB10K/Fold1/train.txt\n",
      "MSLR-WEB10K <_sre.SRE_Match object at 0x3bb6eb8> None\n",
      "/home/zengwei/data/MSLR-WEB10K/Fold1/vali.txt\n",
      "MSLR-WEB10K <_sre.SRE_Match object at 0x3bb6eb8> None\n",
      "/home/zengwei/data/MSLR-WEB10K/Fold1/test.txt\n",
      "MSLR-WEB10K <_sre.SRE_Match object at 0x3bb6918> None\n",
      "train :   0.484709531383 0.1467682225 0.166856131 0.186086626167 0.2052535245\n",
      "vali :   0.487027011575 0.13480473 0.1620579495 0.1829951955 0.2000046395\n",
      "test :   0.481885118212 0.140438064 0.1632816525 0.181485182 0.1987420895\n",
      "train:  0.98 0.98 0.98 0.98 0.97 train :   0.56269544449 0.255998356167 0.27600986 0.292291906167 0.310002294667\n",
      "vali :   0.57190502845 0.2752761395 0.2838886965 0.2992111615 0.312196354\n",
      "test :   0.564148016346 0.2568666165 0.273216586 0.2901187745 0.308149548\n",
      "train:  0.96 0.96 0.96 0.96 0.96 train :   0.558028133976 0.251285659333 0.2712502935 0.287185023167 0.304598057\n",
      "vali :   0.565480470032 0.2521761445 0.2757204165 0.2932129055 0.3071385815\n",
      "test :   0.560330650442 0.2553047115 0.27342693 0.2903545095 0.3060518325\n",
      "train:  0.98 0.98 0.98 0.98 0.98 train :   0.558155068424 0.277085659 0.284359251833 0.299158907 0.3156512985\n",
      "vali :   0.564409986612 0.2743904275 0.2864667645 0.301994708 0.315940324\n",
      "test :   0.559641207216 0.2667951875 0.2807180915 0.297368946 0.312994672\n",
      "train:  0.97 0.97 0.97 0.97 0.97 train :   0.531945898857 0.2627507485 0.277717236 0.2927801155 0.31051916\n",
      "vali :   0.538797004924 0.256019008 0.2762157005 0.2940786245 0.3084378045\n",
      "test :   0.534816329669 0.2687237645 0.285676917 0.298400139 0.3139530735\n",
      "train:  0.99 0.99 0.98 0.98 0.98 train :   0.501471083653 0.2143285335 0.236643461 0.252860158833 0.2699675305\n",
      "vali :   0.51274043689 0.2232237725 0.248252697 0.2624895495 0.2774486245\n",
      "test :   0.506797533192 0.2227666305 0.2423296615 0.2576551175 0.2740493965\n",
      "train:  0.97 0.97 0.97 0.97 0.97 train :   0.543544338045 0.2682856615 0.285128569 0.299967104333 0.317005119833\n",
      "vali :   0.550206583038 0.263342807 0.279618834 0.295811826 0.3136701875\n",
      "test :   0.545419306899 0.2584094745 0.281307601 0.301704957 0.318355977\n",
      "train:  0.98 0.98 0.98 0.97 0.97 train :   0.544084468687 0.250195189 0.272419834167 0.288587913667 0.307023478167\n",
      "vali :   0.548325732533 0.2485523345 0.2692596145 0.2878688695 0.3042512655\n",
      "test :   0.545718164489 0.253871378 0.2743595 0.2922992515 0.3112782835\n",
      "train:  0.98 0.98 0.98 0.98 0.97 train :   0.563308364921 0.287517400667 0.301630297167 0.316553178167 0.333386413667\n",
      "vali :   0.570354127195 0.283499948 0.304389749 0.3194631065 0.3335602135\n",
      "test :   0.567594307675 0.305342796 0.3118802105 0.3256534205 0.3412925545\n",
      "train:  0.98 0.98 0.98 0.98 0.97 train :   0.554615342321 0.279884074833 0.298426178833 0.312786978333 0.330677598333\n",
      "vali :   0.561185928615 0.2650904285 0.292103648 0.3116912395 0.327145269\n",
      "test :   0.557512125551 0.2841904225 0.300914801 0.3170457275 0.334214812\n",
      "train:  0.97 0.97 0.97 0.97 0.96 train :   0.545031345213 0.262092014833 0.277789666167 0.295952424333 0.314749762667\n",
      "vali :   0.551383179993 0.258652338 0.2718084875 0.2916166495 0.3088919855\n",
      "test :   0.549635020152 0.2709523305 0.289066962 0.3058025975 0.323548109\n",
      "train:  0.98 0.98 0.98 0.98 0.98 train :   0.557037260097 0.2715443895 0.287551158 0.300296551667 0.317027290833\n",
      "vali :   0.563182880197 0.2764856705 0.28320161 0.2978293545 0.3129340535\n",
      "test :   0.560445768757 0.2655713815 0.27741469 0.2954662995 0.3145504805\n",
      "train:  0.95 0.95 0.95 0.95 0.94 train :   0.543110763597 0.265893601833 0.282848217667 0.298958402833 0.316926219833\n",
      "vali :   0.548993237 0.261738053 0.2851766825 0.300366351 0.31334183\n",
      "test :   0.547695811354 0.26939043 0.286528318 0.303567516 0.3208706635\n",
      "train:  0.95 0.95 0.95 0.95 0.95"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    dataset = 'MSLR-WEB10K'\n",
    "    fold = 'Fold1'\n",
    "\n",
    "    datafile = '/home/zengwei/data/' + dataset + '/' + fold + '/'\n",
    "\n",
    "    train_data = LoadData(datafile+'train.txt', dataset)\n",
    "    vali_data  = LoadData(datafile+'vali.txt',  dataset)\n",
    "    test_data  = LoadData(datafile+'test.txt',  dataset)\n",
    "\n",
    "\n",
    "\n",
    "    nquery = len(train_data.keys())\n",
    "\n",
    "    Nfeature=136\n",
    "    Learningrate=0.001\n",
    "    Nepisode=100\n",
    "\n",
    "    Lenepisode=10\n",
    "\n",
    "    Resultfile = 'ApprenticeRank/Result_'+dataset+'_'+fold+'_'+time.strftime(\"%m%d\", time.localtime())\n",
    "\n",
    "\n",
    "    learner = RL(Nfeature, Learningrate, Lenepisode, Resultfile)\n",
    "    learner.Eval(train_data, 'train')\n",
    "    learner.Eval(vali_data, 'vali')\n",
    "    learner.Eval(test_data, 'test')\n",
    "    # np.random.seed(datetime.datetime.now().microsecond)\n",
    "\n",
    "\n",
    "    for ite in range(10000):\n",
    "        batch = np.random.randint(nquery,size=Nepisode)\n",
    "\n",
    "        Queryids=[]\n",
    "        for i in batch:\n",
    "            Queryids.append(train_data.keys()[i])\n",
    "\n",
    "        learner.GenEpisodes(Queryids, train_data)\n",
    "        learner.UpPolicy(train_data)\n",
    "        learner.Eval(train_data,'train')\n",
    "        learner.Eval(vali_data,'vali')\n",
    "        learner.Eval(test_data,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
